{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7abba1-2134-4f5b-8f59-5b439204a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import json\n",
    "\n",
    "from data_generation import m_0, g_0, get_data\n",
    "from dml_algorithm import dml_ate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be162aac-eadd-48ad-b7c0-901984f8bba0",
   "metadata": {},
   "source": [
    "## Load tuned hyperparameters of XGBoost for each sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c67795-d538-456f-9d8c-2427c96e4556",
   "metadata": {},
   "source": [
    "Think about it: Do we want to consider this for several/all sample sizes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42382dcc-5a4b-4558-b990-cc1f5af6d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('opt_params_xgboost.json', 'r') as json_file:\n",
    "    opt_params_dict_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98625da7-4675-4146-8e2f-253722a1598d",
   "metadata": {},
   "source": [
    "We consider a sample size of $N=800$. \n",
    "\n",
    "No cross-fitting ($K=0$) means that the ML models are fitted on the entire data set, the optimal hyperparameters for training on a set of size $N=800$ has already been determined in a $5$-fold cross-validation on a data set of size $N=1000$. \n",
    "\n",
    "Similarly, the optimal hyperparameters for performing cross-fitting with $K=2$ folds, i.e. training on a data set of size $N=400$ has been determined in a $5$-fold cross-validation on a data set of size $N=500$.\n",
    "\n",
    "We will perform a $5$-fold cross-validation to determine optimal hyperparameters for ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53f639-02fb-42a0-aca6-009f46571325",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 800\n",
    "\n",
    "settings = {\n",
    "    0: opt_params_dict_dict['1000'],\n",
    "    2: opt_params_dict_dict['500'],\n",
    "    5: None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073b0f9-f418-451c-8714-17d533a4c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_g = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "xgb_model_m = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 25, 50, 75, 100, 150, 200],\n",
    "    'max_depth': [2, 3, 4, 5, 6],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.2, 0.3],\n",
    "    'reg_lambda': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "}\n",
    "\n",
    "grid_search_g = GridSearchCV(estimator=xgb_model_g, param_grid=param_grid, cv=5, n_jobs=-1,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "grid_search_m = GridSearchCV(estimator=xgb_model_m, param_grid=param_grid, cv=5, n_jobs=-1, \n",
    "                             scoring='neg_brier_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4466705-a00b-4010-bbfb-cc0df8d2fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "y_data, d_data, x_data = get_data(N)\n",
    "opt_params_dict = {}\n",
    "    \n",
    "for d in [0, 1]:\n",
    "    grid_search_g.fit(X=x_data[d_data==d], y=y_data[d_data==d])\n",
    "    opt_params_dict[f'g{d}'] = grid_search_g.best_params_\n",
    "   \n",
    "grid_search_m.fit(X=x_data, y=d_data)\n",
    "opt_params_dict['m'] = grid_search_m.best_params_\n",
    "    \n",
    "settings[5] = opt_params_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ba66b-4209-4870-ba92-36e010b3851e",
   "metadata": {},
   "source": [
    "## Infeasible method-of-moments estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adb84e-4add-44f9-b00f-76f35e82b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_ate(y_data, d_data, x_data):\n",
    "    return np.mean(g_0(1, x_data) - g_0(0, x_data) + d_data*(y_data-g_0(1, x_data))/m_0(x_data)\n",
    "                   - (1-d_data)*(y_data-g_0(0, x_data))/(1-m_0(x_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db56ec7-9b27-4d65-aca0-cda74d578741",
   "metadata": {},
   "source": [
    "## DML estimator without cross-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a961b9-09e5-45e8-892a-442c98e5de2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c714830b-6488-4dba-b0f2-321ff84e75ab",
   "metadata": {},
   "source": [
    "## MC simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebafa1f3-5a3f-4dce-99cc-f2405f856f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "n_MC = 5000\n",
    "ate_estimates = np.empty((n_MC, 4))\n",
    "\n",
    "for j in range(n_MC):\n",
    "    y_data, d_data, x_data = get_data(int(N))\n",
    "    ate_estimates[j, 0] = mm_ate(y_data, d_data, x_data)   \n",
    "    for l, (K, opt_params_dict) in enumerate(settings.items()):\n",
    "        model_g0, model_g1 = xgb.XGBRegressor(objective='reg:squarederror'), xgb.XGBRegressor(objective='reg:squarederror')\n",
    "        model_g0.set_params(**opt_params_dict['g0'])\n",
    "        model_g1.set_params(**opt_params_dict['g1'])\n",
    "        model_g = [model_g0, model_g1]\n",
    "        model_m = xgb.XGBClassifier(objective='binary:logistic')\n",
    "        model_m.set_params(**opt_params_dict['m'])\n",
    "        ate_estimates[j, l+1] = dml_ate(K, y_data, d_data, x_data, model_g, model_m, classical=False, inference=False)\n",
    "        \n",
    "np.save('results.npy', ate_estimates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
